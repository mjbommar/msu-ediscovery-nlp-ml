{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbbe1052-34cb-48fa-87ed-f07c669fefc2",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; align: center;\">\n",
    "    <h1>Natural Language and Machine Learning for eDiscovery</h1>\n",
    "    <h2>ELECTRONIC DISCOVERY @ <a href=\"https://www.law.msu.edu/\">MSU Law</a></h2>\n",
    "    <h3>November 7, 2022</h3>\n",
    "    <h3>Lecturer: <a href=\"https://linkedin.com/in/bommarito\">Michael Bommarito</a></h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6680f3ca-6290-4768-ae61-244fb84f3fd0",
   "metadata": {},
   "source": [
    "<h1>First - a time machine:</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194e615b-919c-44ed-a4bc-dc11fe25ad12",
   "metadata": {
    "tags": []
   },
   "source": [
    "![original_2012_intro.png](original_2012_intro.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb22518-1c6f-4153-9856-244cc28fe975",
   "metadata": {},
   "source": [
    "<h2>You can still find this original lecture from 2012 online here: <a href=\"https://www.slideshare.net/mjbommar/natural-language-processing-and-machine-learning-for-discovery\">SlideShare</a></h2>\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4324d1a-3241-4a90-acd4-f78ed2f1fcae",
   "metadata": {},
   "source": [
    "<h1>Our goal for this lecture is unchanged:</h1>\n",
    "\n",
    "<div style=\"font-weight: italic; color: #333; font-size: 150%;\">\n",
    "    <p>To develop a basic understanding of natural language processing (NLP) and machine learning (ML) so that we can effectively:</p>\n",
    "    <ul>\n",
    "        <li><strong>communicate</strong> with clients</li>\n",
    "        <li><strong>communicate</strong> with and select vendors</li>\n",
    "        <li><strong>make strategic decisions</strong> before and during disputes</li>\n",
    "        <li>(better <strong>use</strong> tools ourselves)</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229994fc-334c-496d-9e0f-2c61e5b3f948",
   "metadata": {},
   "source": [
    "<h1>On the other hand, some things <em>have</em> changed...</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92751794-c97e-4eef-afe3-4d8769f66605",
   "metadata": {},
   "source": [
    "![decade_of_ml.png](decade_of_ml.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e96781-7209-48bf-9805-3c023a60bb0e",
   "metadata": {},
   "source": [
    "<h1>&quot;State of the Art&quot; (SotA) in NLP and ML has run a county mile...</h1>\n",
    "\n",
    "<h1>But what about discovery?</h1>\n",
    "\n",
    "<h2>Has - <em>or should</em> - recent technical innovation change FRCP/FRE or related software?</h2>\n",
    "\n",
    "<h3>We'll discuss at the end.</h3>\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0c7aaa-6e16-4334-9e59-78a7bedcf1f0",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h1>But first - the fundamentals.</h1>\n",
    "    <h3>For most attorneys, software - especially eDiscovery - is a black box.</h3>\n",
    "    <h3>You might learn how to turn the dials to get certain outputs, but it's a mystery inside.</h3>\n",
    "    <h4>...and most vendors are happy to create an air of mystery around what proprietary IP is inside.</h4>\n",
    "    <img src=\"black_box_01.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9beb1f-c867-4779-b708-5db1bd9d04fb",
   "metadata": {},
   "source": [
    "<h1>If we look inside, what would we find?</h1>\n",
    "<img src=\"black_box_02.png\" />\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def7e6f3-b634-47de-90c3-eed4b741ace0",
   "metadata": {},
   "source": [
    "<h1>All e-Discovery software essentially boils down to the following two tasks:</h1>\n",
    "\n",
    "<div style=\"font-size: 150%;\">\n",
    "    <ul>\n",
    "        <li>transforming an ESI corpus into a machine representation</li>\n",
    "        <li>transforming a query or search into structured, admissable evidence</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "<h3>In this sense, e-Discovery is no different than what Google does with websites or Finder/Explorer does on your computer.</h3>\n",
    "<h3>The biggest differences are that:</h3>\n",
    "<div style=\"font-size: 125%;\">\n",
    "    <ul>\n",
    "        <li>there are different rules and constraints (FRCP, FRE, etc.),</li>\n",
    "        <li>the stakes are higher (settlement, damages, etc.), </li>\n",
    "        <li>the costs are higher (licenses, billable rates, etc.).</li>\n",
    "    </ul>\n",
    "</div>\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c835909e-64af-441a-811e-2fa661b1429b",
   "metadata": {},
   "source": [
    "<h1><strong>So, why do we need to learn about NLP and ML?</strong></h1>\n",
    "\n",
    "<h2>NLP is how we convert text into machine representation(s) that computers can work with.</h2>\n",
    "\n",
    "<h2>ML is how we search, cluster, or classify these representations in an automated, reproducible way.</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4857085-9423-4cdd-af0e-136810ded0d4",
   "metadata": {},
   "source": [
    "<h1>But are NLP and ML different?</h1>\n",
    "<h2>Yes and no.</h2>\n",
    "<h2>Almost all modern natural language processing rely on at least some machine learning algorithms.</h2>\n",
    "<h2>But most machine learning algorithms are agnostic to the type of data you use them with.</h2>\n",
    "\n",
    "<h3>ML techniques like neural networks/deep learning might work equally well on text, images, or audio data.</h3>\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11255d1-3390-4eb7-8e06-e9af89e56c39",
   "metadata": {},
   "source": [
    "<h1>Let's start with the basics of NLP.</h1>\n",
    "<h1>Here's some example text:</h1>\n",
    "\n",
    "<pre style=\"width: 50%; font-size: 125%;\">Hurricane Sandy grounded 3,200 flights scheduled for today and tomorrow, prompted New York to suspend subway and bus service and forced the evacuation of the New Jersey shore as it headed toward land with life-threatening wind and rain.\n",
    "\n",
    "  The system, which killed as many as 65 people in the Caribbean on its path north, may be capable of inflicting as much as $18 billion in damage when it barrels into New Jersey tomorrow and knock out power to millions for a week or more, according to forecasters and risk experts.\n",
    "</pre>\n",
    "<p style=\"color:#999999;\"><small>Source: Bloomberg news, October 2021</small></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ff8755-501f-4bf5-a4a2-ceba288bd1f9",
   "metadata": {},
   "source": [
    "<h1>How would we describe this text?</h1>\n",
    "<h2>Well, first we'd look at its structure or segments.</h2>\n",
    "<div style=\"font-size: 125%;\">\n",
    "    <ul>\n",
    "        <li><strong>Documents</strong>: 1</li>\n",
    "        <li><strong>Sections</strong>: N/A</li>\n",
    "        <li><strong>Paragraphs</strong>: 2</li>\n",
    "        <li><strong>Sentences</strong>: 2</li>\n",
    "        <li><strong>Clauses</strong>: ...</li>\n",
    "        <li><strong>Words</strong>: ...</li>\n",
    "        <li><strong>Characters</strong>: ...</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7ddaa2-6d4f-4063-b419-c246f6a49b77",
   "metadata": {},
   "source": [
    "<h1>In NLP, this is generally referred to as <strong>segmentation</strong>.</h1>\n",
    "<h3>In particular, segmentation refers to breaking up a corpus into documents, sections, topics, paragraphs, and sentences.</h3>\n",
    "<h3>Based on the nature of communication, some of these types may or not be present.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce4bbdb-19d7-4516-a27b-6ba24907dca5",
   "metadata": {},
   "source": [
    "<h2>Segmentation is important for search and production.</h2>\n",
    "<h3><strong>Hypo:</strong> Should the relevancy of a sentence depend on whether the email is long or short?</h3>\n",
    "\n",
    "<h4>Corpus 1</h4>\n",
    "<pre style=\"width: 50%;\">\n",
    "From: John\n",
    "To: Jane\n",
    "Date: October 12, 2001\n",
    "Subject: Conversation\n",
    "Message: Hi Jane, looking forward to following up on the Cal transaction we discussed yesterday.  If you could share an idea what it would take to get that over the line, I will work with out side to make it happen for you.  BTW, next time you are back to Houston, we'll try to schedule so you can bring the family.  I think you'd love our place in Galveston and we'd be happy to host you there.\n",
    "</pre>\n",
    "\n",
    "<h4>Corpus 2</h4>\n",
    "<pre style=\"width: 50%;\">\n",
    "From: John\n",
    "To: Jane\n",
    "Date: October 12, 2001\n",
    "Subject: Conversation\n",
    "Message: Hi Jane, looking forward to following up on the Cal transaction we discussed yesterday.  \n",
    "\n",
    "If you could share an idea what it would take to get that over the line, I will work with out side to make it happen for you.\n",
    "\n",
    "</pre>\n",
    "\n",
    "<pre style=\"width: 50%;\">\n",
    "From: John\n",
    "To: Jane\n",
    "Date: October 12, 2001\n",
    "Subject: Re: Conversation\n",
    "Message: BTW, next time you are back to Houston, we'll try to schedule so you can bring the family.  \n",
    "\n",
    "I think you'd love our place in Galveston and we'd be happy to host you there.\n",
    "</pre>\n",
    "\n",
    "<h4>Corpus 3</h4>\n",
    "<pre style=\"width: 50%;\">\n",
    "From: John\n",
    "To: Jane\n",
    "Date: October 12, 2001\n",
    "Subject: Conversation\n",
    "Message: thx for chat re: Cal transaction yesterday, pls share what # u think will make it happen\n",
    "</pre>\n",
    "\n",
    "<h3>Be careful to consider how the material is stored and search relative to the original.</h3>\n",
    "<h3>This can get especially tough with so much modern, informal communication intermixed with traditional, longer-form messages.</h3>\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6394f89-6a31-4fc3-9a03-3914b1246a5a",
   "metadata": {},
   "source": [
    "<h2>But whether it's formal/informal or text/email, computers process the smaller units of natural language the same way.</h2>\n",
    "<h3>...and what do we call those units?</h3>\n",
    "<h2><strong>Tokens</strong></h2>\n",
    "<h3>In general, you can think of tokens as if they were words.</h3>\n",
    "<h2>Almost all NLP methods focus on breaking up text into these small units first.</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38a9f55-2494-45c3-92c6-cc2677fd214b",
   "metadata": {},
   "source": [
    "<h1>In NLP, this process is called <strong>tokenization</strong>.</h1>\n",
    "\n",
    "<h2>Let's look at how this actually happens.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64a822c4-8415-475c-9c33-2ad1c47ace69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hurricane', 'Sandy', 'grounded', '3,200', 'flights', 'scheduled', 'today', 'tomorrow', 'prompted', 'New']\n"
     ]
    }
   ],
   "source": [
    "from nlp_ml_examples import get_tokens\n",
    "\n",
    "text = \"\"\"Hurricane Sandy grounded 3,200 flights scheduled for today and tomorrow, \n",
    "prompted New York to suspend subway and bus service and forced the evacuation of \n",
    "the New Jersey shore as it headed toward land with life-threatening wind and rain.\n",
    "\n",
    "The system, which killed as many as 65 people in the Caribbean on its path north, \n",
    "may be capable of inflicting as much as $18 billion in damage when it barrels into \n",
    "New Jersey tomorrow and knock out power to millions for a week or more, according \n",
    "to forecasters and risk experts.\"\"\"\n",
    "\n",
    "text_tokens = get_tokens(text)\n",
    "\n",
    "print(text_tokens[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f51543-a6c2-409c-947b-1162303d43fe",
   "metadata": {},
   "source": [
    "<h1>This is a <strong>list of tokens</strong>:</h1>\n",
    "<pre style=\"font-size:125%;\">['Hurricane', 'Sandy', 'grounded', '3,200', 'flights', 'scheduled', 'for', 'today', 'and', 'tomorrow']</pre>\n",
    "<h2>In particular, it's an <em>ordered</em> list or <em>sequence</em>.</h2>\n",
    "<h3>The first item in this list corresponds to the first token in the text, and so on, for as many tokens as were detected.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eb2248-414f-4b61-bf84-ec61c037ffe8",
   "metadata": {},
   "source": [
    "<h4>PS: This is all real code that you can run on your computer if you install Python.</h4>\n",
    "<h4>Check out <a href=\"https://www.anaconda.com/products/distribution\">Anaconda</a> for an easy way to get everything installed.</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370339c8-67df-4b35-aa31-8bb3988462d8",
   "metadata": {},
   "source": [
    "<h1>Using ordered lists of tokens, we can answer questions like:</h1>\n",
    "<div style=\"font-size: 125%;\">\n",
    "    <ul>\n",
    "        <li>Does the word phrase &quot;quote stuffing&quot; occur in the text?</li>\n",
    "        <li>How many times does &quot;Sandy&quot; occur?</li>\n",
    "        <li>How often does &quot;outage&quot; occur within three words of &quot;power?&quot;</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deaf904d-ab5a-468b-ac42-69a7f69bb77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search result  (position): None\n"
     ]
    }
   ],
   "source": [
    "# Does 'quote stuffing' occur?\n",
    "search_result = None\n",
    "for i in range(len(text_tokens) - 1):\n",
    "    if text_tokens[i] == 'quote' and text_tokens[i+1] == 'stuffing':\n",
    "        search_result = i\n",
    "        \n",
    "print(\"Search result  (position):\", search_result)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcdd9d45-bc94-44ac-b0e2-754d5b92ef01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search result (position): 4\n"
     ]
    }
   ],
   "source": [
    "# Does 'flights scheduled' occur?\n",
    "search_result = None\n",
    "for i in range(len(text_tokens) - 1):\n",
    "    if text_tokens[i] == 'flights' and text_tokens[i+1] == 'scheduled':\n",
    "        search_result = i\n",
    "        \n",
    "print(\"Search result (position):\", search_result)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b27e3d-4597-41e5-8246-d53656fffeba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many times does tomorrow occur?\n",
    "text_tokens.count(\"tomorrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05116c9-2016-46d2-b18a-95eaaa67b596",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<h1>So is NLP really just fancy control-F/âŒ˜-F?</h1>\n",
    "<h2>Often, yes.  But it doesn't have to be.</h2>\n",
    "<h2>Modern NLP allows us to do much more - and some tools expose this possibility, implicitly or explicitly.</h2>\n",
    "<h1>We can also answer questions like:</h1>\n",
    "<div style=\"font-size: 125%;\">\n",
    "    <ul>\n",
    "        <li>Does the name of a person or place occur in the text?</li>\n",
    "        <li>Did someone mention a date or dollar amount?</li>\n",
    "        <li>Were any verbs related to payment used?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1384b1b4-c666-4c6a-bb36-6513a6b68d8b",
   "metadata": {},
   "source": [
    "<h2>In order to answer more &quot;useful&quot; search queries like these, we need to go beyond tokenization.</h2>\n",
    "<h2>We need to learn about:</h2>\n",
    "<div style=\"font-size: 125%;\">\n",
    "    <ul>\n",
    "        <li>Stems and lemmas</li>\n",
    "        <li>Stopwords</li>\n",
    "        <li>Part-of-speech tagging</li>\n",
    "        <li>Parsing sentence structure and dependencies</li>\n",
    "    </ul>\n",
    "</div>\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b05af5d-b020-411a-8c51-d4445dbd6359",
   "metadata": {},
   "source": [
    "<h2>If you know a language like Spanish or German, you already understand stems and lemmas.</h2>\n",
    "<h2><strong>Stems</strong> and <strong>lemmas</strong> are the &quot;base&quot; or &quot;root&quot; of the word - before you decline or conjugate.</h2>\n",
    "<h2>In English, we generally decline for plurality - <em>dog</em> vs. <em>dog<span style=\"color: #33aa33;\">s</span>.</em></h2>\n",
    "<h2>...and conjugate for tense or mood - <em>pay</em> vs. <em>paid</em></h2>\n",
    "<h2>Often, multiple &quot;words&quot; share the same stem or lemma:</h2>\n",
    "<div style=\"font-size: 125%;\">\n",
    "    <ul>\n",
    "        <li>Assign</li>\n",
    "        <li>Assignment</li>\n",
    "        <li>Assignee</li>\n",
    "        <li>Assignor</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7049c4f6-520e-4c0d-9121-a753611b06d1",
   "metadata": {},
   "source": [
    "<h1>Searching based on a stem or lemma can help us search by a <strong>concept</strong>.</h1>\n",
    "<h2>This is a big improvement over simple Control-F/âŒ˜-F.</h2>\n",
    "<h2>Some vendors call this &quot;natural language&quot; search.</h2>\n",
    "<h2>Others call it &quot;conceptual&quot; search.</h2>\n",
    "<h2>Others make up a marketing buzzword.</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb06e36-d1f4-49a4-a01f-2e7f8748f97f",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<h1>Let's look at our prior text as stems/lemmas.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0376564f-b079-49f8-b127-2291cfd627ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hurricane', 'Hurricane'), ('Sandy', 'Sandy'), ('grounded', 'ground'), ('3,200', '3,200'), ('flights', 'flight'), ('scheduled', 'schedule'), ('for', 'for'), ('today', 'today'), ('and', 'and'), ('tomorrow', 'tomorrow')]\n"
     ]
    }
   ],
   "source": [
    "from nlp_ml_examples import get_tokens_and_lemmas\n",
    "\n",
    "text_lemmas = get_tokens_and_lemmas(text)\n",
    "\n",
    "print(text_lemmas[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e433112-10d0-41a8-86b0-0d93af7c9e2e",
   "metadata": {},
   "source": [
    "<h1>Now, we have an ordered list of each pair of (token, lemma).</h1>\n",
    "<h3>[('Hurricane', 'Hurricane'), ('Sandy', 'Sandy'), <span style=\"color: #66aa66; font-weight: bold;\">('grounded', 'ground')</span>, ('3,200', '3,200'), <span style=\"color: #66aa66; font-weight: bold;\">('flights', 'flight')</span>, <span style=\"color: #66aa66; font-weight: bold;\">('scheduled', 'schedule')</span>, ('for', 'for'), ('today', 'today'), ('and', 'and'), ('tomorrow', 'tomorrow')]</h3>\n",
    "<br />\n",
    "<h3>This lets us search for when the stems/lemmas occur, not just the exact words.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3384cd17-1589-471b-8a30-d1c5e12dc007",
   "metadata": {},
   "source": [
    "<h2>There are a bunch of &quot;junk&quot; words though.  Wouldn't be nice if we could focus on the signal instead of noise?</h2>\n",
    "<h3>This is where <strong>stopwording</strong> comes in.</h3>\n",
    "<h3>Stopwords are, subjectively, words that don't matter.</h3>\n",
    "<h3>Ideally, they're semantically empty things that play only grammatical functions.</h3>\n",
    "<h3>For example: auxiliary verbs, prepositions, conjunctions, etc.</h3>\n",
    "<h3>In practice, stopwords can be anything you want that occurs as noise.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bce6e66f-555d-44be-b852-8b860c970d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hurricane', 'Sandy', 'grounded', '3,200', 'flights', 'scheduled', 'today', 'tomorrow', 'prompted', 'New']\n"
     ]
    }
   ],
   "source": [
    "text_tokens_no_stopwords = get_tokens(text, remove_stopword=True)\n",
    "\n",
    "print(text_tokens_no_stopwords[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02b9770-6341-426f-bb80-a58d96c651e2",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<h2>After removing stopwords, we're normally left with the &quot;main&quot; nouns and verbs in a sentence.</h2>\n",
    "<h2>But if we really want, we can look specifically at the parts-of-speech of our tokens.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b102a250-2336-4d33-bae7-b4d0a6d6e14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hurricane', 'PROPN'), ('Sandy', 'PROPN'), ('grounded', 'VERB'), ('3,200', 'NUM'), ('flights', 'NOUN'), ('scheduled', 'VERB'), ('for', 'ADP'), ('today', 'NOUN'), ('and', 'CCONJ'), ('tomorrow', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "from nlp_ml_examples import get_tokens_and_pos\n",
    "\n",
    "text_pos = get_tokens_and_pos(text)\n",
    "\n",
    "print(text_pos[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff37659-8b58-47c9-a94a-d84b1594fd96",
   "metadata": {},
   "source": [
    "<h1>Now, we have an ordered list of each pair of (token, part of speech).</h1>\n",
    "<h3>[('Hurricane', 'PROPN'), ('Sandy', 'PROPN'), ('grounded', 'VERB'), ('3,200', 'NUM'), ('flights', 'NOUN'), ('scheduled', 'VERB'), ('for', 'ADP'), ('today', 'NOUN'), ('and', 'CCONJ'), ('tomorrow', 'NOUN')]</h3>\n",
    "<h3>For example, we could filter this list to only show VERB tokens.</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5e39268-a565-4ea3-aaee-cd378d854a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grounded\n",
      "scheduled\n",
      "prompted\n",
      "suspend\n",
      "forced\n",
      "headed\n",
      "threatening\n",
      "killed\n",
      "inflicting\n",
      "barrels\n",
      "knock\n",
      "according\n"
     ]
    }
   ],
   "source": [
    "for token, pos in text_pos:\n",
    "    if pos in ['VERB']:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fad87c9-7e96-45cd-b77c-00cb34a3299e",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<h2>In addition to parts of speech, we often care about the &quot;special&quot; nouns.</h2>\n",
    "<h2>If you dig deep into elementary school memories, you might remember what makes a proper noun proper.</h2>\n",
    "<h3>The people, places, and things are often at the heart of relevancy (or privilege).</h3>\n",
    "<h2>Proper nouns - as well as things like dates - can be found by searching for <strong>named entities</strong>.</h2>\n",
    "<h2>The task of finding named entities is often referred to as <strong>named entity recognition</strong> (NER).</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f999137-389b-46dd-8458-1a90daf88651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3,200', 'CARDINAL'),\n",
       " ('today', 'DATE'),\n",
       " ('tomorrow', 'DATE'),\n",
       " ('New', 'GPE'),\n",
       " ('York', 'GPE'),\n",
       " ('New', 'GPE'),\n",
       " ('Jersey', 'GPE'),\n",
       " ('as', 'CARDINAL'),\n",
       " ('many', 'CARDINAL'),\n",
       " ('as', 'CARDINAL'),\n",
       " ('65', 'CARDINAL'),\n",
       " ('Caribbean', 'LOC'),\n",
       " ('as', 'MONEY'),\n",
       " ('much', 'MONEY'),\n",
       " ('as', 'MONEY'),\n",
       " ('$', 'MONEY'),\n",
       " ('18', 'MONEY'),\n",
       " ('billion', 'MONEY'),\n",
       " ('New', 'GPE'),\n",
       " ('Jersey', 'GPE'),\n",
       " ('tomorrow', 'DATE'),\n",
       " ('millions', 'CARDINAL'),\n",
       " ('a', 'DATE'),\n",
       " ('week', 'DATE')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nlp_ml_examples import get_tokens_and_ner\n",
    "\n",
    "get_tokens_and_ner(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53679e88-75eb-468e-99e0-fc2026d541e8",
   "metadata": {},
   "source": [
    "<h2>Note how some of these named entities occur across multiple tokens:</h2>\n",
    "<div style=\"font-size: 125%;\">\n",
    "    <ul>\n",
    "        <li>as many as 64</li>\n",
    "        <li>as much as $18 billion</li>\n",
    "        <li>New Jersey</li>\n",
    "        <li>New York</li>\n",
    "        <li>a week</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51fd71c-2d5f-4efa-aa0a-387c8e2e7aa3",
   "metadata": {},
   "source": [
    "<h1>This information lets us pose queries that we could never address with Control-F.</h1>\n",
    "<div style=\"font-size: 125%;\">\n",
    "    <ul>\n",
    "        <li>Find all emails where a date between July 15 and July 18 was mentioned.</li>\n",
    "        <li>Find all texts that mentioned Las Vegas and an amount over $5 million.</li>\n",
    "        <li>Find all documents that mention a geopolitical entity like a state or country.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc801483-52ca-4d5c-b12b-ad74a46a121f",
   "metadata": {},
   "source": [
    "<h1>But do any of these NLP methods <strong>really understand</strong> concepts or semantics?</h1>\n",
    "<h2>For example, <em>stock</em> and <em>option</em> don't share the same stem/lemma but are clearly related.</h2>\n",
    "<h3>And does an NLP model have any way of knowing that both are related to securities generally?</h3>\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e122076b-0c29-41c7-bcd0-53e72dfa0302",
   "metadata": {},
   "source": [
    "<h1>Enter stage left: embeddings, vectors, tensors, transformers, and LLMs.</h1>\n",
    "<h2>Except, in e-Discovery, they haven't.  SotA in NLP has outpaced e-Discovery adoption.</h2>\n",
    "<h2>There are some valid reasons.  But there's also plenty of opportunity...</h2>\n",
    "<h2>Let's ignore e-Discovery for a moment.  What can NLP actually do today?</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7591f345-c9f5-43b0-94e7-1fee56c4d851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token1</th>\n",
       "      <th>token2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>0.655527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>frog</td>\n",
       "      <td>dog</td>\n",
       "      <td>0.595764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>frog</td>\n",
       "      <td>hound</td>\n",
       "      <td>0.582690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>frog</td>\n",
       "      <td>cat</td>\n",
       "      <td>0.564689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mammal</td>\n",
       "      <td>dog</td>\n",
       "      <td>0.451694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hound</td>\n",
       "      <td>cat</td>\n",
       "      <td>0.421805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hound</td>\n",
       "      <td>dog</td>\n",
       "      <td>0.421734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mammal</td>\n",
       "      <td>frog</td>\n",
       "      <td>0.418958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mammal</td>\n",
       "      <td>cat</td>\n",
       "      <td>0.398267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mammal</td>\n",
       "      <td>hound</td>\n",
       "      <td>0.390460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>box</td>\n",
       "      <td>dog</td>\n",
       "      <td>0.324666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>box</td>\n",
       "      <td>cat</td>\n",
       "      <td>0.321953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>box</td>\n",
       "      <td>frog</td>\n",
       "      <td>0.306349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>box</td>\n",
       "      <td>hound</td>\n",
       "      <td>0.148043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>box</td>\n",
       "      <td>mammal</td>\n",
       "      <td>0.125586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token1  token2  similarity\n",
       "0      cat     dog    0.655527\n",
       "3     frog     dog    0.595764\n",
       "5     frog   hound    0.582690\n",
       "4     frog     cat    0.564689\n",
       "6   mammal     dog    0.451694\n",
       "2    hound     cat    0.421805\n",
       "1    hound     dog    0.421734\n",
       "9   mammal    frog    0.418958\n",
       "7   mammal     cat    0.398267\n",
       "8   mammal   hound    0.390460\n",
       "10     box     dog    0.324666\n",
       "11     box     cat    0.321953\n",
       "13     box    frog    0.306349\n",
       "12     box   hound    0.148043\n",
       "14     box  mammal    0.125586"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "from nlp_ml_examples import nlp\n",
    "\n",
    "example_doc = nlp(\"dog cat hound frog mammal box\")\n",
    "\n",
    "token_similarity = []\n",
    "\n",
    "# get all combinations of two words\n",
    "for i, token1 in enumerate(example_doc):\n",
    "    for token2 in example_doc[0:i]:\n",
    "        # don't compare a word to itself\n",
    "        if token1 != token2:\n",
    "            token_similarity.append((token1, token2, token1.similarity(token2)))\n",
    "        \n",
    "token_similarity_df = pandas.DataFrame(token_similarity, columns=[\"token1\", \"token2\", \"similarity\"])\n",
    "token_similarity_df.sort_values(\"similarity\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a48dcbb-f1a9-4297-892c-eb4989fa9ee6",
   "metadata": {},
   "source": [
    "<h1>How did the computer know this?</h1>\n",
    "<h3>But also why is frog~hound > hound~dog?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bade9fbe-f0a5-4b2f-b831-8935d582618b",
   "metadata": {},
   "source": [
    "<img src=\"bert.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcafc7b-6e45-4595-afcd-470b031c057e",
   "metadata": {},
   "source": [
    "<h2>SotA NLP models rely on very large datasets of human-produced text.</h2>\n",
    "<h2>Imagine if someone had every word written on Wikipedia in every language</h2>\n",
    "<h2>...plus every version of every website every written - including links</h2>\n",
    "<h2>...plus every email, tweet, text, and Facebook message  ever sent</h2>\n",
    "<h2>...plus every image-caption pair ever posted</h2>\n",
    "<h2>...plus a transcript of every YT/FB/TikTok video ever posted</h2>\n",
    "<h1>Could a computer figure out conceptual relationships from that much information?</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f354624-498f-40e7-b09a-727d834cc9d7",
   "metadata": {},
   "source": [
    "<h2>Well, that's basically how we got:</h2>\n",
    "<div style=\"font-size: 125%;\">\n",
    "    <ul>\n",
    "        <li>word2vec and doc2vec</li>\n",
    "        <li>BERT, Albert, and Roberta</li>\n",
    "        <li>XLNet</li>\n",
    "        <li>GPT-2 and GPT-3</li>\n",
    "        <li>BLOOM</li>\n",
    "        <li>DALL-E and Stable Diffusion</li>\n",
    "        <li>...and a new SotA model on ðŸ¤— nearly every week.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5560048e-06eb-4426-ac20-ab3399fa6d30",
   "metadata": {},
   "source": [
    "<h2>To my knowledge, no e-Discovery platform uses deep learning.</h2>\n",
    "<h3>Some platforms uses word2vec models (&quot;shallow&quot; learning).</h3>\n",
    "<h3>Some <strong>pre-</strong>Discovery platforms may be innovating.</h3>\n",
    "<h2>There are good reasons.</h2>\n",
    "<h3>Most deep learning models are comparatively random.</h3>\n",
    "<h3>Keyword and traditional NLP search produce more predictable results.</h3>\n",
    "<h3>Deep learning is also more expensive to run at the scale on real-world data.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8bccb2-3e0c-48e5-b80f-d6a12cd1bdf9",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<h1>OK, but what about Machine Learning (ML)?</h1>\n",
    "<h1>Machine Learning and NLP in 30 seconds:</h1>\n",
    "<div style=\"font-size: 155%;\">\n",
    "    <ul>\n",
    "        <li>SotA NLP relies entirely on deep learning.</li>\n",
    "        <li>Deep learning is an extreme form of neural networks.</li>\n",
    "        <li>Neural networks are one of the original types of machine learning.</li>\n",
    "        <li>Machine learning is really just statistics - theory + lots of data.</li>\n",
    "        <li>Statistics is really just squinting your eyes and trying to draw a line through a bunch of points.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fb9f19-3b21-4f0c-a88b-b77dbf1b1bc3",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<h1>More seriously, machine learning is focused on three types of tasks:</h1>\n",
    "<h2>Group stuff together in unknown categories - <strong>Clustering</strong></h2>\n",
    "<h2>Group stuff together into known categories - <strong>Classification</strong></h2>\n",
    "<h2>Guess how much something will be based on stuff - <strong>Regression</strong></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abe7efd-490c-4325-9177-a040006a8c02",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<h1>Sometimes, we perform these tasks just once.</h1>\n",
    "<h3>We collect a lot of high-quality training data.</h3>\n",
    "<h3>For example, we might have radiologists review CT scans to mark lesions in lungs.</h3>\n",
    "<h3>We then note which of these lesions were found to be malignant or benign.</h3>\n",
    "<h3>Using this data, we train a machine learning model to identify lesions and classify them as malignant or benign.</h3>\n",
    "<h3>Finally, we use this model for all new CT scans performed.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3446eb1e-4f9b-48f7-9a92-a4a7677145c5",
   "metadata": {},
   "source": [
    "<h1>Other times, we continue teaching the model over time.</h1>\n",
    "<h3>We load a 100K messages and documents into Relativity.</h3>\n",
    "<h3>We review a random sample of 100 items, marking which are relevant.</h3>\n",
    "<h3>We ask Relativity to propose 100 more relevant documents, reviewing and correct theses.</h3>\n",
    "<h3>...repeat, until stopping criteria met or all documents reviewed.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0e2ca1-f6d7-4f10-82d9-704c9e29d016",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<h1>Sometimes, we care about labels. Other times, just similarity.</h1>\n",
    "<h3>When we care about labels like privilege or relevance, we use classification.</h3>\n",
    "<h3>When we care about similarity without labels, we use clustering.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdb33b3-e42b-4d8c-9a1a-6ee08884154d",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<h1>What else differentiates e-Discovery systems?</h1>\n",
    "<h2>UI/UX - Is the interface easy to learn, easy to use, easy to customize?</h2>\n",
    "<h2>De-duplication and versioning</h2>\n",
    "<h2>Supported languages</h2>\n",
    "<h2>Optical character recognition (OCR)</h2>\n",
    "<h2>File formats, e.g., Word, WordPerfect, PDF, HTML</h2>\n",
    "<h2>Integration into systems like Office 365, Google Apps, messaging apps</h2>\n",
    "<h2>Ability to scale to very large production</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5589da93-7d08-44c5-87c0-8dd08ce228c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
